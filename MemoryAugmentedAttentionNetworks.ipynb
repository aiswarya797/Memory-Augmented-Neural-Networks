{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MemoryAugmentedAttentionNetworks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1JN_2mOteG43OHETZDo87QgUnG7u4llZu",
      "authorship_tag": "ABX9TyPpkXDCoTl3r5mSwJY5Eh9P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aiswarya797/Memory-Augmented-Neural-Networks/blob/master/MemoryAugmentedAttentionNetworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTxJJPYBCMVx"
      },
      "source": [
        "* Check the data input and output \n",
        "  * what is the embedding which needs to be used?\n",
        "  * The output sizes can be different\n",
        "  * In what way data has to be inputted?\n",
        "* What is the loss function to be used?\n",
        "* Is the memory to attention?\n",
        "\n",
        "* References:\n",
        "\n",
        "  -- https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/sequences/nmt_with_attention.ipynb\n",
        "  \n",
        "  -- https://www.guru99.com/seq2seq-model.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "ZwX30oZUB6jA",
        "outputId": "02582263-b0f9-4924-e1d2-23bb57d50fef"
      },
      "source": [
        "## Data Set Loader\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def Convert(string): \n",
        "    list1=[] \n",
        "    list1[:0]=string \n",
        "    return list1 \n",
        "\n",
        "def generate_seq(filename, write_in_file=False):\n",
        "  character_sequence = []\n",
        "  subword_sequence = []\n",
        "\n",
        "  if(write_in_file):\n",
        "    f = open(\"/media/aiswarya/New Volume/My_works/MANN/Model0/Data/SeqData.txt\",\"w\")\n",
        "    \n",
        "  file_ = open(filename, 'r') \n",
        "  lines = file_.readlines() \n",
        "  for line in lines:\n",
        "    temp = line.split(':')\n",
        "    if len(temp)<=2:\n",
        "      t = line.split(',')\n",
        "      temp = t[0].split(':')\n",
        "    char_seq = temp[0].strip()\n",
        "    subwrd_seq = temp[1].strip()\n",
        "    subword_sequence.append(subwrd_seq)\n",
        "    character_sequence.append(char_seq)\n",
        "    if(write_in_file):\n",
        "        f.write(\"%s\\t%s\\n\"%(char_seq,subwrd_seq))\n",
        "  if(write_in_file):\n",
        "    f.close()\n",
        "  return character_sequence,subword_sequence\n",
        "\n",
        "def load_data(data_file):\n",
        "    f = open(data_file)\n",
        "    line = f.readline()\n",
        "    X = []\n",
        "    Y = []\n",
        "    while line:\n",
        "        info = line.strip(\"\\n\").split(\"\\t\")\n",
        "        x = info[0]\n",
        "        y = info[1]\n",
        "        X.append(x)\n",
        "        Y.append(y)\n",
        "        line = f.readline()\n",
        "    f.close()\n",
        "    return X,Y\n",
        "\n",
        "def train_test_split(X,Y, split_rat = 0.8):\n",
        "  length = len(X)\n",
        "  train_size = int(length*0.8)\n",
        "  test_size = length-train_size\n",
        "  X_train = X[0:train_size]\n",
        "  Y_train = Y[0:train_size]\n",
        "  X_test = X[train_size:]\n",
        "  Y_test = Y[train_size:]\n",
        "\n",
        "  return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "def find_distinct_tokens(data,separator, write_in_file, write = False):\n",
        "  tok2ind = {}\n",
        "  ind2tok = {}\n",
        "  all_tok = []\n",
        "  for d in data:\n",
        "    info = d.split(separator)\n",
        "    all_tok.extend(info)\n",
        "    \n",
        "  all_tok = list(set(all_tok))\n",
        "  all_tok.sort()\n",
        "  all_tok.extend([\"<START>\",\"<END>\"])\n",
        "  print(\"all_tok\")\n",
        "  if write:\n",
        "    f = open(write_in_file,\"w\")\n",
        "    for ind,item in enumerate(all_tok):\n",
        "      tok2ind[item] = ind\n",
        "      ind2tok[ind] = item\n",
        "      f.write(\"%s\\t%d\\n\"%(item,ind))\n",
        "    f.close()\n",
        "  else:\n",
        "    for ind,item in enumerate(all_tok):\n",
        "      tok2ind[item] = ind\n",
        "      ind2tok[ind] = item\n",
        "  return tok2ind,ind2tok\n",
        "\n",
        "def load_tokens(token_file):\n",
        "    f = open(token_file)\n",
        "    line = f.readline()\n",
        "    tok2ind = {}\n",
        "    ind2tok = {}\n",
        "    while line:\n",
        "        info = line.strip(\"\\n\").split(\"\\t\")\n",
        "        item = info[0]\n",
        "        ind = int(info[1])\n",
        "        tok2ind[item] = ind\n",
        "        ind2tok[ind] = item\n",
        "        line = f.readline()\n",
        "    return tok2ind,ind2tok\n",
        "\n",
        "def string2index(datestring,tok2ind,separator):\n",
        "    components = datestring.split(separator)\n",
        "    return [tok2ind[i] for i in components]\n",
        "\n",
        "def batch_generator(x_data,y_data,batch_size,source_tok2ind,target_tok2ind):\n",
        "    total = len(x_data)\n",
        "    print('total : ', total)\n",
        "    start = 0\n",
        "    # i = 0\n",
        "    while True:\n",
        "        end = min(start + batch_size , total)\n",
        "        X = x_data[start:end]\n",
        "        Y = y_data[start:end]\n",
        "        batch_x = []\n",
        "        batch_y = []\n",
        "        for bx,by in zip(X,Y):\n",
        "            bx = string2index(bx,source_tok2ind,\"-\")\n",
        "            by = string2index(by,target_tok2ind,\",\")\n",
        "            batch_x.append(bx)\n",
        "            batch_y.append(by)\n",
        "        yield np.asarray(batch_x),np.asarray(batch_y),start,end\n",
        "        # print(np.asarray(batch_x), '  ',np.asarray(batch_y),'  ', start, '  ', end)\n",
        "        start = end\n",
        "        if(start >= total):\n",
        "            start = 0\n",
        "            \n",
        "        # i+=1\n",
        "    # return np.asarray(batch_x), np.asarray(batch_y)\n",
        "\n",
        "## Test ##\n",
        "\"\"\"\n",
        "X,Y = generate_seq(\"drive/My Drive/AttentionModel/datafile.txt\", False)\n",
        "print(len(X))\n",
        "print(len(Y))\n",
        "\n",
        "print(X[160], '      ', Y[160])\n",
        "print(X[1010], '     ', Y[1010])\n",
        "print(X[10], '      ', Y[10])\n",
        "print(X[234], '     ', Y[234])\n",
        "print(X[513], '      ', Y[513])\n",
        "print(X[798], '     ', Y[798])\n",
        "\n",
        "ST, SI = find_distinct_tokens(X, '-', \"\", False)\n",
        "TT,TI = find_distinct_tokens(Y, ',', \"\", False)\n",
        "bx, by = batch_generator(X,Y,5,ST,TT)\n",
        "bx = np.array(bx).flatten().tolist()\n",
        "by = np.array(by).flatten().tolist()\n",
        "\n",
        "for i in range(len(bx)):\n",
        "  print(bx[i])\n",
        "  print(SI[bx[i]])\n",
        "\n",
        "for i in range(len(by)):\n",
        "  print(by[i])\n",
        "  for j in range(len(by[i])):\n",
        "    y = by[i][j]\n",
        "    print(TI[y])\n",
        "\"\"\"\n",
        "### OUTPUT ###\n",
        "\"\"\"\n",
        "188749\n",
        "188749\n",
        "शही        शही\n",
        "गधा       ग,धा\n",
        "पौढ़        पौ,ढ़\n",
        "थ्र       थ्र\n",
        "जाय        जाय\n",
        "हौं       हौ,ं\n",
        "all_tok\n",
        "all_tok\n",
        "total :  188749\n",
        "109714\n",
        "बस\n",
        "184335\n",
        "०\n",
        "39670\n",
        "खचा\n",
        "145053\n",
        "लिया।\n",
        "49826\n",
        "चकी\n",
        "[3617]\n",
        "बस\n",
        "[6064]\n",
        "०\n",
        "[1325, 1675]\n",
        "ख\n",
        "चा\n",
        "[4651, 5938]\n",
        "लिय\n",
        "ा\n",
        "[1634, 1133]\n",
        "च\n",
        "की\n",
        "\n",
        "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
        "  return array(a, dtype, copy=False, order=order)\n",
        "\"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n188749\\n188749\\nशही        शही\\nगधा       ग,धा\\nपौढ़        पौ,ढ़\\nथ्र       थ्र\\nजाय        जाय\\nहौं       हौ,ं\\nall_tok\\nall_tok\\ntotal :  188749\\n109714\\nबस\\n184335\\n०\\n39670\\nखचा\\n145053\\nलिया।\\n49826\\nचकी\\n[3617]\\nबस\\n[6064]\\n०\\n[1325, 1675]\\nख\\nचा\\n[4651, 5938]\\nलिय\\nा\\n[1634, 1133]\\nच\\nकी\\n\\n/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\\n  return array(a, dtype, copy=False, order=order)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AeI7suAFDK0"
      },
      "source": [
        "import tensorflow as tf\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "REDUCE = 1\n",
        "\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "if(physical_devices):\n",
        "    tf.config.experimental.set_virtual_device_configuration(physical_devices[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4xpJb6AO7gf"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input,LSTM,Reshape,Conv2D,Flatten, GRU"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcabQ5iePDRK"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, enc_units, vocab_size, embedding_dim=32, nb_layers=3):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.enc_units = enc_units\n",
        "        self.nb_layers = nb_layers\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.all_layers = []\n",
        "        for l in range(self.nb_layers):\n",
        "            layer = tf.keras.layers.GRU(self.enc_units, return_sequences=True,\n",
        "                                        return_state=True, recurrent_initializer='glorot_uniform', dropout=0.2)\n",
        "            self.all_layers.append(layer)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        x = self.embedding(inputs)\n",
        "        for l in range(len(self.all_layers)):\n",
        "            output, state = self.all_layers[l](x)\n",
        "            x = output\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self, batch_size):\n",
        "        return tf.zeros((batch_size, self.enc_units))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kEXMrqSPFoH"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh6AvAwEPOSW"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units,memory_size= 20,memory_vector_dim= 4,head_num= 2, nb_layers=3):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.nb_layers = nb_layers\n",
        "        self.all_layers = []\n",
        "        for i in range(self.nb_layers):\n",
        "          layer = GRU(units=128,return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform', dropout=0.2)\n",
        "          self.all_layers.append(layer)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        self.memory_size = memory_size\n",
        "        self.memory_vector_dim = memory_vector_dim\n",
        "        self.head_num = head_num\n",
        "        self.gamma = 0.95\n",
        "        self.reuse = True\n",
        "\n",
        "        # used for attention\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "  \n",
        "    def read_head_addressing(self, k, prev_M):    \n",
        "\n",
        "        # print('k shape : ', k.shape)\n",
        "        k = tf.expand_dims(k, axis=3)\n",
        "        # print('expand k shape : ', k.shape)\n",
        "        # print('M shape : ', prev_M.shape)\n",
        "        inner_product = tf.matmul(prev_M, k)\n",
        "        # print('inner pd shape : ', inner_product.shape)\n",
        "        k_norm = tf.sqrt(tf.reduce_sum(tf.square(k), axis=2, keepdims=True))\n",
        "        # print('k norm shape : ', k_norm.shape)\n",
        "        M_norm = tf.sqrt(tf.reduce_sum(tf.square(prev_M), axis=3, keepdims=True))\n",
        "        # print('M norm shape : ', M_norm.shape)\n",
        "        norm_product = M_norm * k_norm\n",
        "        # print('norm pd shape : ', norm_product.shape)\n",
        "        K = tf.expand_dims(tf.expand_dims(tf.squeeze(inner_product / (norm_product + 1e-8)), axis = 0), axis=0)\n",
        "        # print('K squeeze shape : ', K.shape)                \n",
        "        K_exp = tf.exp(K)\n",
        "        w = K_exp / tf.reduce_sum(K_exp, axis=1, keepdims=True)    \n",
        "        # print('w shape : ', w.shape)                   \n",
        "        \n",
        "        return w\n",
        "\n",
        "    #weight vector for write operation\n",
        "    def write_head_addressing(self,sig_alpha, prev_w_r_list, prev_w_lu):\n",
        "        prev_w_r = prev_w_r_list[-1]\n",
        "        return sig_alpha * prev_w_r + (1. - sig_alpha) * prev_w_lu     \n",
        "\n",
        "    #least used weight vector\n",
        "    def least_used(self,w_u):\n",
        "        _, indices = tf.nn.top_k(w_u, k=self.memory_size)\n",
        "        w_lu = tf.reduce_sum(tf.one_hot(indices[:, -self.head_num:], depth=self.memory_size), axis=2)\n",
        "        return indices, w_lu\n",
        "\n",
        "\n",
        "    #next we define the function called zero state for initializing all the states - \n",
        "    #controller state, read vector, weights and memory\n",
        "    def zero_state(self,batch_size,dtype):\n",
        "        one_hot_weight_vector = np.zeros([batch_size,1, self.memory_size])\n",
        "        one_hot_weight_vector[..., 0] = 1\n",
        "        one_hot_weight_vector = tf.constant(one_hot_weight_vector, dtype=tf.float32)\n",
        "        with tf.compat.v1.variable_scope('init', reuse=self.reuse):\n",
        "            state = {\n",
        "                'read_vector_list': [tf.zeros([batch_size,1, self.memory_vector_dim])\n",
        "                                      for _ in range(self.head_num)],\n",
        "                'w_r_list': [one_hot_weight_vector for _ in range(self.head_num)],\n",
        "                'w_u': one_hot_weight_vector,\n",
        "                'M': tf.constant(np.ones([batch_size,1, self.memory_size, self.memory_vector_dim]) * 1e-6, dtype=tf.float32)\n",
        "            }\n",
        "            return state\n",
        "\n",
        "    def call(self, x, hidden, enc_output, prev_state):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output) #(batch_size, hidden_size)\n",
        "        prev_read_vector_list = prev_state['read_vector_list']\n",
        "        context_vector = tf.reshape(context_vector, (context_vector.shape[0], 1, context_vector.shape[1]))\n",
        "        context_vector = tf.concat([context_vector] + prev_read_vector_list, axis=-1)\n",
        "        \n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "        # print('embedded x shape : ', x.shape)\n",
        "\n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size +prev_read_size)\n",
        "        x = tf.concat([context_vector, x], axis=-1)\n",
        "        # print('final x shape : ', x.shape)\n",
        "        \n",
        "        # passing the concatenated vector to the GRU\n",
        "        layer_output = x\n",
        "        for l in range(len(self.all_layers)):\n",
        "\n",
        "            output, state = self.all_layers[l](layer_output)\n",
        "            layer_output = output\n",
        "\n",
        "        network = Sequential()\n",
        "        network.add(LSTM(units=128,activation='tanh',return_sequences=True))\n",
        "        layer_output = network(layer_output)\n",
        "\n",
        "        \n",
        "        num_parameters_per_head = self.memory_vector_dim + 1\n",
        "        total_parameter_num = num_parameters_per_head * self.head_num\n",
        "        \n",
        "        #Initiliaze weight matrix and bias and compute the parameters\n",
        "        weights = tf.Variable(tf.random.normal([layer_output.get_shape()[0],layer_output.get_shape()[2], total_parameter_num], stddev=0.35))\n",
        "        # print('weights para : ', weights.shape)\n",
        "        biases = tf.Variable(tf.zeros([total_parameter_num]))\n",
        "        parameters = tf.compat.v1.nn.xw_plus_b(layer_output, weights, biases)\n",
        "        # print('parameters : ', parameters.shape)\n",
        "        head_parameter_list = tf.split(parameters, self.head_num, axis=2)\n",
        "        # print('head parameter list : ', np.array(head_parameter_list).shape)\n",
        "        \n",
        "        \n",
        "        #previous read weight vector\n",
        "        prev_w_r_list = prev_state['w_r_list']   \n",
        "        # print('w_r weights : ', prev_w_r_list[1].shape)\n",
        "        \n",
        "        #previous memory\n",
        "        prev_M = prev_state['M']\n",
        "        # print('memory : ', prev_M.shape)\n",
        "        \n",
        "        #previous usage weight vector\n",
        "        prev_w_u = prev_state['w_u']\n",
        "        # print('usage weights : ', prev_w_u.shape)\n",
        "        \n",
        "        #previous index and least used weight vector\n",
        "        prev_indices, prev_w_lu = self.least_used(prev_w_u)\n",
        "        \n",
        "        #read weight vector\n",
        "        w_r_list = []\n",
        "        \n",
        "        #write weight vector\n",
        "        w_w_list = []\n",
        "        \n",
        "        #key vector\n",
        "        k_list = []\n",
        "    \n",
        "        #now, we will initialize some of the important parameters that we use for addressing.     \n",
        "        for i, head_parameter in enumerate(head_parameter_list):\n",
        "            with tf.compat.v1.variable_scope('addressing_head_%d' % i):\n",
        "                \n",
        "                #key vector\n",
        "                k = tf.tanh(head_parameter[:,:, 0:self.memory_vector_dim], name='k')\n",
        "\n",
        "                #sig_alpha\n",
        "                sig_alpha = tf.sigmoid(head_parameter[:,:, -1:], name='sig_alpha')\n",
        "                \n",
        "                #read weights\n",
        "                w_r = self.read_head_addressing(k, prev_M)\n",
        "                \n",
        "                #write weights\n",
        "                w_w = self.write_head_addressing(sig_alpha, prev_w_r_list[i], prev_w_lu)\n",
        "           \n",
        "            w_r_list.append(w_r)\n",
        "            w_w_list.append(w_w)\n",
        "            k_list.append(k)\n",
        "            \n",
        "        # print('new w_R : ', w_r_list[0].shape)\n",
        "        #usage weight vector \n",
        "        w_u = self.gamma * prev_w_u + tf.add_n(w_r_list) + tf.add_n(w_w_list)   \n",
        "\n",
        "        #update the memory\n",
        "        M_ = prev_M * tf.compat.v1.expand_dims(1. - tf.one_hot(prev_indices[:,:, -1], self.memory_size), dim=3)\n",
        "        \n",
        "        #write operation\n",
        "        M = M_\n",
        "        with tf.compat.v1.variable_scope('writing'):\n",
        "            for i in range(self.head_num):\n",
        "                \n",
        "                w = tf.expand_dims(w_w_list[i], axis=3)\n",
        "                k = tf.expand_dims(k_list[i], axis=2)\n",
        "                M = M + tf.matmul(w, k)\n",
        "\n",
        "        #read opearion\n",
        "        read_vector_list = []\n",
        "        with tf.compat.v1.variable_scope('reading'):\n",
        "            for i in range(self.head_num):\n",
        "                read_vector = tf.reduce_sum(tf.compat.v1.expand_dims(w_r_list[i], dim=3) * M, axis=2)\n",
        "                read_vector_list.append(read_vector)       \n",
        "\n",
        "        \n",
        "        #controller output\n",
        "        new_state = {\n",
        "            'read_vector_list': read_vector_list,\n",
        "            'w_r_list': w_r_list,\n",
        "            'w_w_list': w_w_list,\n",
        "            'w_u': w_u,\n",
        "            'M': M,\n",
        "        }\n",
        "\n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        # output shape == (batch_size, vocab)\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights, new_state"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxTpVrNz6QwT"
      },
      "source": [
        "class Seq2SeqMANN:\n",
        "    def __init__(self, name, in_vocab_size, out_vocab_size, embedding_dim, units, batch_size):\n",
        "        self.name = name\n",
        "        self.units = units\n",
        "        self.batch_size = batch_size\n",
        "        self.encoder = Encoder(units, in_vocab_size)\n",
        "        print(\"Encoder Dimensions \", self.encoder)\n",
        "        self.decoder = Decoder(out_vocab_size, embedding_dim, units)\n",
        "        self.decoder_state = self.decoder.zero_state(self.batch_size, tf.float32)\n",
        "        print(\"Decoder Dimensions \", self.decoder)\n",
        "        self.optimizer = tf.keras.optimizers.Adam(\n",
        "            0.0001)  # tf.keras.optimizers.RMSprop(0.0001)\n",
        "        self.saver = tf.train.Checkpoint(\n",
        "            encoder=self.encoder, decoder=self.decoder, optimizer=self.optimizer)\n",
        "        self.save_dir = \"drive/My Drive/AttentionModel/Weights/\"+self.name+\".ckpt\"\n",
        "        self.weight_manager = tf.train.CheckpointManager(\n",
        "            self.saver, self.save_dir, max_to_keep=2)\n",
        "        self.loss_list = []\n",
        "\n",
        "    def loss_function(self, pred, real):\n",
        "\n",
        "        loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "            from_logits=True, reduction='none')\n",
        "\n",
        "        loss_ = loss_object(real, pred)\n",
        "        return tf.reduce_mean(loss_)\n",
        "\n",
        "    def train_step(self, inp, targ, start_index, end_index):\n",
        "        loss = 0\n",
        "        batch_size = inp.shape[0]\n",
        "\n",
        "        pred_output = []\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = self.encoder(inp)\n",
        "            dec_hidden = enc_hidden\n",
        "            dec_input = tf.expand_dims([start_index] * batch_size,1)  #start index = index of <START>\n",
        "            # Teacher forcing - feeding the target as the next input\n",
        "            # print('targ :', targ.shape)\n",
        "            # print('targ,shape[1] : ', targ.shape[1])\n",
        "            for t in range(0, targ.shape[1]):\n",
        "                # passing enc_output to the decoder\n",
        "                prediction, dec_hidden, att_wt, state = self.decoder(dec_input, dec_hidden, enc_output, self.decoder_state)\n",
        "                loss += self.loss_function(prediction, targ[:, t])\n",
        "                self.decoder_state = state\n",
        "                # using teacher forcing\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1) #tf.math.argmax(prediction), 1)\n",
        "                # if(target[t] == end_index):\n",
        "                #   break\n",
        "        \n",
        "        # batch_loss = (loss / int(targ.shape[1]))\n",
        "        variables = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "        self.loss_list.append(loss) \n",
        "        return loss\n",
        "\n",
        "    def gnrl(self, inp, targ, start_index, max_length, target_ind2tok):\n",
        "        enc_output, enc_hidden = self.encoder(inp)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([start_index] * self.batch_size,1)  #start index = index of <START>\n",
        "\n",
        "        result = ''\n",
        "        for t in range(max_length):\n",
        "            prediction, dec_hidden, attention_weights, state = self.decoder(dec_input, dec_hidden, enc_output, self.decoder_state)\n",
        "            # storing the attention weights to plot later on\n",
        "            attention_weights = tf.reshape(attention_weights, (-1,))\n",
        "            # attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "            predicted_id = tf.math.argmax(input = prediction).numpy()\n",
        "            \n",
        "            max = -1\n",
        "            for i in predicted_id:\n",
        "              if(max<i):\n",
        "                max = i\n",
        "\n",
        "            predicted_id = max\n",
        "            print('Predicted ID : ', predicted_id)\n",
        "            result += target_ind2tok[predicted_id] + ' '\n",
        "\n",
        "            if target_ind2tok[predicted_id] == '<END>':\n",
        "                return result, targ#, attention_plot\n",
        "\n",
        "            # the predicted ID is fed back into the model\n",
        "            dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        return result, targ#, attention_plot\n",
        "\n",
        "\n",
        "    def train(self, X, Y, source_tok2ind, target_ind2tok, target_tok2ind, epochs):\n",
        "        restore_from = tf.train.latest_checkpoint(self.save_dir)\n",
        "        self.saver.restore(restore_from)\n",
        "        print('Weights restored from %s' % restore_from)\n",
        "\n",
        "        total = len(X)\n",
        "        batches = batch_generator(X, Y, self.batch_size,\n",
        "                                    source_tok2ind, target_tok2ind)\n",
        "        nbbatches = int(np.ceil(total / float(self.batch_size)))\n",
        "        print(\"Ready to generate batches: Total %d #Batches %d\" %\n",
        "                (total, nbbatches))\n",
        "        best_loss = np.inf\n",
        "        print('epochs', epochs)\n",
        "        i = 1\n",
        "        print('Iteration : ', i)\n",
        "        for e in range(epochs):\n",
        "            total_loss = 0\n",
        "            for b in range(nbbatches):\n",
        "                batch_x, batch_y, start, end = next(batches)\n",
        "                if batch_x.shape[0] == self.batch_size:\n",
        "                  b_loss = self.train_step(\n",
        "                      batch_x, batch_y, start_index=target_tok2ind['<START>'], end_index=target_tok2ind['<END>'])\n",
        "                  total_loss += b_loss\n",
        "                i+=1\n",
        "                if i%50==0:\n",
        "                  t = np.arange(0,i-1,1)\n",
        "                  plt.plot(self.loss_list, t)\n",
        "                  plt.show()\n",
        "                if i%10==0:\n",
        "                    self.predict(batch_x, batch_y, target_tok2ind['<START>'], 5,source_ind2tok, target_ind2tok)\n",
        "                    print('Iteration : ', i)\n",
        "                    print('Loss : ', b_loss)\n",
        "            total_loss = total_loss/nbbatches\n",
        "            print(\"\\tEpoch %d/%d Loss %0.4f\" % (e+1, epochs, total_loss))\n",
        "            if(total_loss < best_loss):\n",
        "                self.weight_manager.save()\n",
        "                best_loss = total_loss\n",
        "                print(\"--------------New Best State-----------------\")\n",
        "\n",
        "    def predict(self, inp, targ, start_index, max_length, source_ind2tok, target_ind2tok):\n",
        "\n",
        "        # print(inp)\n",
        "        result, targ = self.gnrl(inp, targ, start_index, max_length, target_ind2tok)\n",
        "        # print('Input: ', source_ind2tok[inp[0][0]])\n",
        "        print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "480hfdFpJBed",
        "outputId": "decdcc28-4132-4e55-f9b1-73e15271c8df"
      },
      "source": [
        "X, Y = generate_seq(\"drive/My Drive/AttentionModel/datafile.txt\", False)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)\n",
        "\n",
        "source_tok2ind, source_ind2tok = find_distinct_tokens(X, '-', write_in_file=\"/media/aiswarya/New Volume/My_works/MANN/Model0/Data/source_tokens.txt\", write=False)\n",
        "target_tok2ind, target_ind2tok = find_distinct_tokens(Y, ',',  write_in_file=\"/media/aiswarya/New Volume/My_works/MANN/Model0/Data/target_tokens.txt\", write=False)\n",
        "\n",
        "print(source_ind2tok[0])\n",
        "\n",
        "Nc_out = len(target_tok2ind)\n",
        "print('Nc Out : ', Nc_out)\n",
        "Nc_in = len(source_tok2ind)\n",
        "print('Nc In : ', Nc_in)\n",
        "\n",
        "network = Seq2SeqMANN('MANN', Nc_in, Nc_out, embedding_dim=32, units=128, batch_size=1)\n",
        "\n",
        "# train network \n",
        "network.train(X_train, Y_train, source_tok2ind, target_ind2tok, target_tok2ind, 50)\n",
        "# network.test(X_tes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all_tok\n",
            "all_tok\n",
            "$िकताबें\n",
            "Nc Out :  6224\n",
            "Nc In :  185457\n",
            "Encoder Dimensions  <__main__.Encoder object at 0x7f771a71d7d0>\n",
            "Decoder Dimensions  <__main__.Decoder object at 0x7f771816e790>\n",
            "Weights restored from None\n",
            "Ready to generate batches: Total 150999 #Batches 150999\n",
            "epochs 50\n",
            "Iteration :  1\n",
            "total :  150999\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted translation:      \n",
            "Iteration :  10\n",
            "Loss :  tf.Tensor(17.472015, shape=(), dtype=float32)\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted translation:      \n",
            "Iteration :  20\n",
            "Loss :  tf.Tensor(17.471066, shape=(), dtype=float32)\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted translation:      \n",
            "Iteration :  30\n",
            "Loss :  tf.Tensor(8.73604, shape=(), dtype=float32)\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted translation:      \n",
            "Iteration :  40\n",
            "Loss :  tf.Tensor(8.735721, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted translation:      \n",
            "Iteration :  50\n",
            "Loss :  tf.Tensor(17.471035, shape=(), dtype=float32)\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted translation:      \n",
            "Iteration :  60\n",
            "Loss :  tf.Tensor(17.465855, shape=(), dtype=float32)\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted translation:      \n",
            "Iteration :  70\n",
            "Loss :  tf.Tensor(17.458965, shape=(), dtype=float32)\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted translation:      \n",
            "Iteration :  80\n",
            "Loss :  tf.Tensor(17.45842, shape=(), dtype=float32)\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted translation:      \n",
            "Iteration :  90\n",
            "Loss :  tf.Tensor(26.200394, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2de7AkVZ3nv7+TVXX73u6mb79omubRMCJOC+tI3HFwVMThIeKMoGEYzhpOi8z0OuG4qDiKOrG6se4EOrMz68buOtvri1lZHjrMgrOMioiiGyPS0IBCi92gSDePvkhj0/R9VGWe/SMzq05mZVZlVlbdzFP3+4m4UVW/PJn5q7xZ33PynN/5HdFagxBCyHihynaAEELI8KG4E0LIGEJxJ4SQMYTiTgghYwjFnRBCxpBa2Q4AwIYNG/TWrVvLdoMQQqzinnvueUZrvTFpWyXEfevWrdi1a1fZbhBCiFWIyGNp29gtQwghY0hfcReRL4rIQRH5iWFbJyK3icje4HVtYBcR+S8isk9EHhCRs0bpPCGEkGSytNy/DOCimO0qALdrrU8DcHvwGQDeAOC04G8HgM8Nx01CCCF56CvuWus7ATwbM18C4Jrg/TUALjXsf699fghgWkQ2D8tZQggh2Ri0z32T1vrJ4P1TADYF77cAeNwotz+wdSEiO0Rkl4jsmp2dHdANQgghSRQeUNV+5rHc2ce01ju11jNa65mNGxMjeQghhAzIoOL+dNjdErweDOwHAJxolDshsBFCCFlCBhX3WwBsD95vB3CzYf+jIGrmbAC/NrpvCLGKv/+XX+CW+58o2w1CBqLvJCYRuQ7AuQA2iMh+AJ8AcDWAG0XkcgCPAXhbUPxWABcD2AfgKIDLRuAzIUvCV3ftx/RUHW962fFlu0JIbvqKu9b6D1M2nZdQVgN4b1GnCKkCpx+3Gt/7GQf7iZ1whiohKbzo2FWYfX4Bz883y3aFkNxUIrcMIVVk85oVAID/esc+bFg5AaUENSVQSuBI571pc5T/l2Rr/6XZnNi2BJsSQERKvjLEBijuhKSwbfMxaNQU/sf3Hi3blQjxCkIJUHMUVFDhOEqgFFBTyt+mlF/RKMBRCk7bFhwrsDlKBWXSbOF5fVtYsSXZor4YNsd/dVJs4Tm6bJHjmr6HFW23zVGyrCtCijshKZy2aTUe/PevR8vVaHkePA9wdee9aXM9D24OW/s1zeZ6cHXH5mmNlqsj5UObF/jkeoDnabS80KbheRpuis31NJquh5bnRmz+OWJ/hi08h2mrKkq6BT/tiSleCSXZBqqYejyVnb5pNc77zU39v8gAUNwJ6UHdUag7AOCU7UpPtM4mzG2BDoS+y+bGhDxSgSTbPE+j6Wosuh4WW/5f0/Ww0PK6bIuBbSHBFpYL3y+0vMLXxdOA5/r+VZGXHEdxJ2TJeebIAr5+/xNYbHlBazomlAm2IgLpJtjMbeHxkmwVbjxnHqeYrDtYOVHLPE5hdv3Ebe0uo1gLO+JLlw1wHBXxs9OVZZ5nAFv7ScDvEgttK2qji2mhuBOSwv/ZfQCf+r97uuwiaD+WJ/UJZx1AVUpQdxRW1KO2iDgl2CJdAynnzetLl62PeGYS1MBGyoHiTkgKUw3/5/GdK1+L46cnIwJMSNWhuBOSwvRUHQCw0PKwol7tPndC4nASEyEpTDV8QT+66JbsCSH5obgTkkLYLTNHcScWQnEnJIW64/etN93iIXmELDUUd0JScIKB01aV4wwJSYHiTkgKYXfMJAdTiYVQ3AlJYa4ZiHuDPxNiHwyFJCSF+abf137Xz5/F04cXBp48lDVDpGLGRzJEKO6EpLB6hf/z+Mw3Hl6yc+abat/J+GhOoQ8zJLazQVqU8THPjFpWhL2huBOSwqtetAE/+MjrMLfoJifk6srvkjGHTGKWxiADpDbe97SFGSCTbZ4HHG21DFt3PpqsWSCrigoyPvZLfzC0fPtFUjGk5LZZO9XAa07bMJKKiuJOSA9OWDtVtgtDw8wcGU9ZnJbGuOX5lVMka2OQubFpZHds28wMjwmZHiP7uLHMkEbGyNDWq24JMz4CGgtLdhWHiwhwx5XnYuuGlUM/NsWdkBQWWx6+v3cWRxddeDqakTFseZut3ayt42FljkzOThm28BOEvLqNcCNvj9+d1HAUphq1oKsm1tUkRveSsQBJtGXdbcvTwl+SVr8jOGZFHcdPT47kmlLcCUnhmw8+hfddt3vg/ePZHQdZFMIXE4WJWjYRMYWrPFHrn+rWtCkOJI8EijshKYQzU7902W/jpHVTudY+ZeZIUjYUd0JSUEFr8uR1Uzh146qSvSEkH5ydQUgKYdqBusOfCbEP3rWEpDAfzFBtjHApNEJGBe9aQlI4+PwClADrVzbKdoWQ3FDcCUlh9vkFrFvZQI3dMsRCeNcSkoLreexvJ9bCO5eQFDwNMKCR2ApDIclYYk61b88CDWZqJtkiM0MD26EXFis9q5OQXlDcLULHp6abU+FjU9N72oyp6Um2zIml3HB6e+BXgs2cah+3Rab0Z/U9MtW+1xT/4VzzrevHJ7cMWV4UEncR+QCAPwagAfwYwGUANgO4HsB6APcAeKfWerGgn4lorfHgE4cx13T7ZuzrZTNbbXFbW7h6CWqCLW++kSy+6Iq2IkUwlOx6SgnqjsKKevd0enMaf9w2aJ711BS0xqzTU0aQ0ImQpWBgcReRLQD+LYBtWus5EbkRwNsBXAzgb7XW14vI3wG4HMDnhuJtjG8++BTe85V7R3HoSlFTgsm6g7qj0Kj5SZUmav5709aoxd4btrDchGGvx/aZSLDFj1PjVHtCrKBot0wNwKSINAFMAXgSwO8B+NfB9msAfBIjEvcLth2Hr1z+O5hvpuTbHpNWesvTaC26ANxRXMZchK30fgmx+rWk87Tsy0yIdcLaSWxYNVH2ZSckNwOLu9b6gIj8NYBfApgD8C343TDPaa1bQbH9ALYU9jIFRwlefdqGUR2+VMxKYlz711ueh4WW4V8FU9mevH4K3/vz143uBISMiCLdMmsBXALgFADPAfgqgIty7L8DwA4AOOmkkwZ1Y2xRSqAgqDtle1J90hahCCNj4jYvqCz62a6965f44aO/KvvrETIQRbplzgfwc631LACIyE0AXgVgWkRqQev9BAAHknbWWu8EsBMAZmZmKjpUSGxAgkHRzs08nBrxXx75Fe782exQjkXIUlNkEtMvAZwtIlPiZ9o/D8BDAO4A8NagzHYANxdzkZByUErgVTVEiZA+DCzuWuu7AHwNwL3wwyAV/Jb4RwB8UET2wQ+H/MIQ/CRkyXFEKr1ANCG9KBQto7X+BIBPxMyPAnhFkeMSUgXqjoKnAdfTcBjuSSyDuWUISSHM477QKj8ElZC8UNwJSWEiEPfFlleyJ4Tkh+JOSAoNijuxGIo7ISmEkTJMr0BshOJOSApNN1ggW/FnQuyDKX/JssdMlWDmCDq60Oq/MyEVheI+hmjt5zOPTK/3EOSX6bb5OVuy29qvhi2ac8aDq5E/50xMZCMJ2XLkwTETwMVtpp/h+36w4U5sxHpx//XRJhZa7kCJtEYlFmktwfzClZ4sy9zWJeQVnnfTL6d71AbUlIplcwxtQEM5bZujFBwVKy8CR8W2xWyOUoE/cZvv6/HTk1i9ol72ZSMkN1aL+x0/PYjLvnx32W6MHEdJV772qUZ3Dvd6LNe7bxM0HKddzs/ZHh7P8d8HedwHXfSiV8pc06bEzwNDCBk9Vov7zNa1+I9vPgPzTS9/azlvytuYLc9ycKYvg+B6GnOei7nm6CbTiCD3CkaZ8q7L8HKr513ZyYlVUuaKS6m22HdeOeFgosbUnMQ+rBb31SvqeMfvnFy2G7noqlQyrgk6cJeQq7HgelhseWgGr4stD4tu7NXc7npYSLAttjzMLbrt9wvLIP772NUT+NHHzy/bDUJyY7W4A8DRxRaarbCFbAz+tQUz7J82BTOfrd9gYVWfFFxd7XVXh/2kMOxVmBwRnMwFsomlWC3u3/vZLC770o8qPYA4DJL63JPWTa1H1kIVY1vQ5x6x+eULd3/E1lQ1bWkLWXPdVUJGj9Xi/lsnTOMv3rgN8y23b1dF8lqnsWiUvrb0CBXXQxDe50W2hectwij73DtiG0aTADWnE1USRqaE23wR744q6fyl2/r1x9dSbIMO9KZWVDF7YiUVHLPhKNQcxkIS+7Ba3NdM1fHuV59Stht9icedJ/azF+h7H1mIZobxATOGvdn04HpuJIZ9qQadR8Vk3cHtV74Wx09Plu0KIbmwWtxtQUSC1iyjLrKQd9B5VJXcQ08cxk27D+DQ0UWKO7EOijupHFVZHPzm+w7gpt0H2ql/CbEJ3rWEpHB43s8tc8wkZ6gS+6C4E5LCcy8sAgCmJxsle0JIfijuhKQQLtbRdMd/shYZP9jnvkzJkjlylJPBhhbBkxBRZEbwxG15InjCFZheWGhh5QR/KsQuxuqO7RVl0SuiIj4DNPLjT7BlFpv4uRNsmdPhxmzLKXOkGXvfyRljxOUHmSDN2PswPr9eV4Vi749dvQIbV0+UfUkIyY3V4n7PY4fwri/9CHOLbqWn2hel3wzVyXot2OYkzlCtKZVrBqo5oShuY+ZIQuzAanE/ef0U3vW7W3F00R3JRJ48uV9GWbkUnaEqgqioisDpkTYgbovnbBlVHpe8GR/T/Ey1GRVPr+9DyDhgtbhvWDWBKy88vWw32iR1C3VVNAldQKPuFiqarMy0NV0Pc81svvfys8rdQkmV1bCeepIqmqILikRsCsF5jPftSs7vqnKSbBEfO7Z+35lPWdXFanGvGlWZfGMDWhevaLIMnKYOpppjGW1bMEbRp7LqlAsHib0Umw5WCUOskvfHPPJUuFVFSbQSyJI/KN61N5Lc/UalnJS7Pzxeki3+VNvziTHFVoWnQoo7KQUJfli8AfsTRjb1rOSSKq0sg/LGtoEr2B5PoeY5mq6/PsBCbE2B6DoDGoutzpoBFa7XBiJSsSjB9Mo6btjxypGkt+Bvi5ABWfKFVxJsPbvo+iR6y/20kxax1T5eeuRWlUV6mNFZZiRWp7usY4s/2UxPNrBmRDOgKe6kjdlCTBWrAgJWdVEbp4VQhtHVoZSg7iisqMe6OoyuiyRb3vMyOms0jL2429K3a9qS+nY7LaJuWzuu3cg7b/btticlmb64XreQV7h5paR3bnlzsLDzQw5aTrEfeL2uBuovzRoVNLTB1/iiJykLocQjoRjxQwDLxX33Lw/hfdftxnzTTW3FVVivSiFs1dQdhZojWFF3UHd80ag7CvUgJr5eU6irjr2mBDXHj5/3P6v2fp334T7+sRux/WpKRY4X+hDuH36Obw9FS6TT0jJfVdDyUgnbCVmuWC3uxx6zAueevhELTQ8a/kpIWne6F9qf4bduPa2h0dmet5wO7J7ulEP4OdyuO/uH5SL7aRg+BnYvYT8NQIfvQ3+KX7Ow0lsOi1sD6BJ7QbQSEEmuFNLKdb2i89msbLo+R8qFx04u1/GjUw6mn+1jRct1/IwfK385MfzrV4Ga5SLXTgEC6fq+WctFrnHQhQJ0rlVXOeMameVS/3finzf1f9anXNUpJO4iMg3g8wDOAKABvBvAwwBuALAVwC8AvE1rfaiQlylsmZ7Epy49cxSHriS6XQkZoh9UFpFKwItXFAnljM+dijGsZPKXg/E5rVzXZxiVnGHvVGqxcl547GhF2t4PfkXphRV1QjmN4LMX+xwrB6OiTysXbxC098tQzg26zOINErMcEPt+se/Rr+GQ2uCINRz4dDsYSZWCWQlEKuT4a1DutE2rcc27XzES/4q23D8L4Bta67eKSAPAFICPAbhda321iFwF4CoAHyl4HoJOCxIAHFS/5bDcyD0QnMGWNQ5+GOGKTc8fi2m6/nhNy+2EL/qhjP72MKyxFZQL7eF+tlcW8TV9nSxjHzJYHP2Ljl01uu8x6I4isgbAOQDeBQBa60UAiyJyCYBzg2LXAPguKO7EQp4+PI93feluHJ5rZoryqSoi6D25x7ClDQQ3HIXJeoHB4RRb1+B1LN2Fk2LritbJOIjdc7KSjNdgdJGW+ykAZgF8SUReBuAeAFcA2KS1fjIo8xSATUk7i8gOADsA4KSTTirgBiGjYe/TR7DnycN47Ys3YtMxEwNHzwxtJmaWfEAJgmpD/zAZPkXEvQbgLADv01rfJSKfhd8F00ZrrUUksUmjtd4JYCcAzMzMVLfZQ5Yt80Gitg9e8GK87MTpkr0hJB9FVmLaD2C/1vqu4PPX4Iv90yKyGQCC14PFXCSkHOZbvrhPNpgsiNjHwOKutX4KwOMiEqZlPA/AQwBuAbA9sG0HcHMhDwkpifmmHy66okZxJ/ZRNFrmfQCuDSJlHgVwGfwK40YRuRzAYwDeVvAchJRCLRhca3nLY04AGS8KibvW+j4AMwmbzityXEKqQLhu6pGFVsmeEJKfIn3uhIw1Lddvsdcd/kyIffCuJSSFZ48uAgDWTjVK9oSQ/FDcCUnBCeLD/Yn7hNgFxZ2QFNat9Fvszzy/WLInhOSH4k5IClMNf0A1jHcnxCYo7oSkEGZm5OR9YiMUd0JSaAbRMjVGyxALsXqxDlI+ScsYdpb967ZFliU0bW58QWVzMeZkW3vpQWN5wfar1l02/9xJNt1eltC0HTw8DwCYrHOGKrEPinsCw1jVviNqndSwblvACi4AvQQ5vrOet8KZbhMXQ86zqv1Uw8EF2zbh5PVTZX8VQnJjtbjvO3gEf3nrHswtulzVPmvaWFXOqvZmOtyhr2qf4KOyZCk0QkaF1eLe8jwcmW9hvuUWar1WVcxDHCX+AtJKjXRVmFRbbDGDWootj5gXXVSBYk5Ib6wW95ccdwxufM8rCx/H7H5I65rI9CRgVC5JtqTuDbNbJMtqP4Mu5dbyPCy0TF+MPuv2ORDrk/a7XVqeB6/dj13dmrBoN4zTtgXHUgrTk3X85VvOxKoJq38qZBnCOxbByuoQcNysP+FCzhHBb3dtdds6g5pmxZLPFh238ODq6HqlrZSxjCLjFs2mh18dmcOdvzqKHeecijO2rCn70hOSC4o7yYWIwBHAUeNfE95073588Mb72WonVsIAXkL6UN2OKELSobgTksL0VB0A8Ou5ZsmeEJIfijshKUwEy+stNJlbhtgHxZ2QFML0A/UafybEPnjXEpJCmDjMYfw8sRCGAZCRkpR7JjlNw+hyz3TCI2M5aPrYDjw3V/blI2RgKO4DEI+ZLpL/pV/umaQY7o6AZZ/E1MunYeWeSbJVeM5Tplm1Lz3+GJy4jrlliH1YLe6PP3sU//27+zDf9PqLWo+UBFkEzLRVFRF00g+E0/zNlASGrV9umDD3TK98MXFbdCZo8nkLp0fI4HvWlAmEjDNWi/vskQX8v32/wnzTjT3OG61cr/q5Y/rhKEHDUWjUFOqOwkTNf9+xCRo1hZpSXUnC0hKHOe1p+KaohtPwk2yA46hAQAObQnBMlWgLp/pnsUVEPsHmKGHuGEJyYLW4n3XSWtz54df1Lad1tEWfmAvGjbX2k7oz+jwBpD0VJJ+708ebZOscK7SFU+69RJvnAUdbrejU/AG7iqqKkm7BT2ulF80+GR5/eqqOKy88HSuYm4JYhtXinhUJWqI1/j77EuaOiVda8aehrkorPg6QVGHmqGwGqzCNyjrBZh5rseX1Tdz2wkILh4428aaXbcGZJzC3DLGLZSHuJDud3DHsAvn6/U/gfdftxoo6I4aJffCuJSSFlsc1VIm98K4lJIV6IOqtYKYqITZBcSckhZryfx6LFHdiIRR3QlIIxx1sD6UlyxOKOyEphGPKVQ4PJSSNwuIuIo6I7BaRfwo+nyIid4nIPhG5QUQaxd0kZOkJW+4um+7EQobRcr8CwB7j86cB/K3W+kUADgG4fAjnIGTJUcGMWI8td2IhhcRdRE4A8EYAnw8+C4DfA/C1oMg1AC4tcg5CyoLZDojNFG25/2cAHwYQhhOsB/Cc1roVfN4PYEvSjiKyQ0R2iciu2dnZgm4QMnzCBjtFntjIwDNUReT3ARzUWt8jIufm3V9rvRPATgCYmZnhc+8yx0x70CtNQVe6gAypCvJk/DTz8Txy8AgAPyEaIbZRJP3AqwC8SUQuBrACwDEAPgtgWkRqQev9BAAHirtpJ/GEZXkTeBXNv5JV1PolLAsXvUiyhYtndGxGMjONdlKzaM4ZL1HIq8jqiRqOO2ZF2W4QkpuBxV1r/VEAHwWAoOX+Ia31O0TkqwDeCuB6ANsB3DwEPxN59oVF3HD345GUv2miliepVBZbPJGWbamGsyxU0S+bYvjXqNUGy6seS0NcS7Gpdirgblsks2POPO9dueITbErAVMPESkaROOwjAK4XkU8B2A3gCyM4BwDgwSd+jb/+1sOVbfUNCzOfu5nHPZ7PvVFz0AjyvXdsCg3HCV6DvO+OShfrmC01L7wTW5wjyWZUCkkLdlA8CRkdoivQvJyZmdG7du0aaN+m21mFqUgO84htyMvdDS3NrXHOyHd1MzxplP9vTqXI6kp+ax2RhUBCW7h4SJKt/SrS07Z+1QTe/tsnsgIilURE7tFazyRtsz7lb91R4DoK/TEXqm4vMt3uL++2RRaeTrH5lYexeEgvmxvrlx/F+rBaY67pDmVg1eTsU9fjlA0rS/rPETIY1os7yUZ7wZK2hTViLzxP4+sPPIErrr8PTSYOIxbCGC9CElBK2il/vQp0XRKSF4o7ISmEou6wv51YCMWdkBQEQW4ZNtyJhbDPnVSerggoHR0MTRsoLTrX4cEnDgMAFlpuyVeAkPxQ3EsgnGofiUQJokoikSjtEMcw+sQUomy2LhFMsMWjU/qFiPayZYmCaQtsgi3pHGV2edeUYPWKenkOEDIgVov70cUW/umBJzEfC38bphDlFad2eKFnTNGPC3mFH/PjseVK/AWio5OTgthxCWPUjThx6cSt1+sKUzFbu7xgyWalmjNx47Zw8lUkdt6YnTvZcCjuxEqsFve7Hn0WH/7aA2W7MXLMGar1YAZqkRmq4XHMY0zUFGpKwXEGS0nQS4TDYxFClg6rxf11LzkWu/7ifCy0vO5+VmMmZ5It7G81c8EMNQdN7IkgbeZr39mtCeeYb7p4YbGVWK6qUXsiyJf3JSnlgdkKH3FrP/xbt7KBC7dt4gxVYh1WizsAbFg1UbYLlWJYg4/J2SNHV8nl6R5ruh7mm1n77ot3j93xoXM5Q5VYh/XiTqIoJVCQsU7JEK/AiuQUaroeFlvBnxt9/fH+X+Om3Qew2OIMVWIfFPcKEI+eMVuew46eieZcD1u5ft6Xfi3prtwuAwrqMPO+jBolwJpJDqgS+7Ba3BdaLr6z52A0WZSOikWRkMDMCava4mUubBGeo3f0TJUXqgCiGRvNtL1Z+suj+eKBRt2JDcR2Mjaatkg2x5gtKYtjNC2xYWunIE62qeB4oc38HqE/aybrWM+uP2IhVov793/2DP702nvLdmPkjCJaxt/XaZebSIigqTsqV/pdRscQUh2sFvfzt23CnX/+Osy3EuLcewzu5ekyGEY3QtE+YtOXo4stPD+/zFZ7GiDP+7AibTatnsArTlnHaBliHVaLOwCctH6qbBeGSlK0S69KKYweWQgGBZuxQcGkgcKw3EKCLa38ouuhGbwuGLZelUvL04Cnsbh0l2/o1JTg7o+fj7UrG2W7QkgurBb3puvh+3tnMbfoFR4sTFokYpSDhdFB046tqi1xEURa1o2awmTDSW5tjzBOfZD+/qRZqf2eGELbupUNCjuxEqvF/fY9T+M9X2Gf+6j63M33NUe1B0ZrSkUWkzbTEbD7gpBqYLW4v/6lx+FbHzgnObdMKX3osWiZvrbwicKLRtBEnij8ba6nMbfo4ohuVT+6Jib4YW6aTnRMttw0Zh6afrlpktZWLdLXH9rWrmxg5uS1rLSIdVgt7iKCF29aXbYbS04YF9+zXz7nAHKWENLCA8U5k7k1mx5cz01OHdF3ZmrHp6J858rX4tSNq4bwnyNk6bBa3JcrItJuzZL+9Bqk7lWhfX/vLP7y1p9ikWuoEguhuJOxZ9CUDI/MHvH3Z5cMsRCKOxkrhtll9ejsCwCAllvdMQ5C0qC4W4COZ0YM+50NQcq0mEifPveqDTanZXN0PXQNNpvfYdg0alxqmNiH1eLueRq7Hz+E+WZUIBLzv1R0Fmok1j7FVtXYd6B7FqqTsKpR0kpH8XwuNaWwoh6LWjGO19PWa4ZqwQia6ak6fmMj0/0S+7Ba3P/5J0/hvf+bce7DWompV5x7POdMw1HMH0NIhbFa3N9wxnG48d+80o9z7xNW1282av4MkNlsWZ4AerX2w26HOc/FXNMt+5JH6DcbNWqLZYBUfsRPOztjJKY9jHtPs4XnDbI9DimmPWm26/RUA6cft/zCbYn9WC3uSgleccq6st0YKWF/e+GEZ+1KLlyFyKzkkm1hn3enkov1h2e2dSZrJdk8z08l0fLc1Iova8U6Cm77wDk4bRnOpyB2Y7W4Lwck6J/mP6o/ZqRMrvGUlOX8dj9+CJ/5xsN4fqFV9lcjJDfUDDI2DHty10LL7war8oA2IWkMHOMlIieKyB0i8pCIPCgiVwT2dSJym4jsDV7XDs9dQpYO5pMhNlMkgLcF4Eqt9TYAZwN4r4hsA3AVgNu11qcBuD34TIjFsOlO7GNgcddaP6m1vjd4/zyAPQC2ALgEwDVBsWsAXFrUSULKQLf7Y9iCJ/YxlKl3IrIVwMsB3AVgk9b6yWDTUwA2DeMchJQFe2eIjRQWdxFZBeAfALxfa33Y3Kb9pk/iM62I7BCRXSKya3Z2tqgbhAydsM+dA6rERgqJu4jU4Qv7tVrrmwLz0yKyOdi+GcDBpH211ju11jNa65mNGzcWcYOQkRAG3WiqO7GQItEyAuALAPZorf/G2HQLgO3B++0Abh7cPULKI5wUxagZYiNF4txfBeCdAH4sIvcFto8BuBrAjSJyOYDHALytmIuElIMXtNi5KAqxkYHFXWv9A6SHEZw36HEJWSp6rdDkehrPHW365dgtQyyEM1THiHD6vZn73PMQpCfuvO8IWJjrxczRks/WnsqvNVzXzCxOymAAAAvdSURBVBmTnritKznbgHlkiqZpzkpdMZ87sQ/rxf3g8/NYaHqpiycnLmyRYMssLPG1NxNsxTNOxhaxMBJ+9VrEYkR5s4ZCPNtikQySjbrTtoWZIcPy0QySwauRQTLJFskzH/oQ2NZM1vHS448p+/IRkhurxf3m+w7giuvv619wBIggd/rYJFFTSlB3OgtVRFLTBvsm2SLnSzmHaYssqBGzJYlafEGNVFuGNLpKOChJyFJjtbgfPLwAAPgPl56BlQ1nMFHLsnJQXMCCbYQQUlWsFveQN798C1ZNjMVXIYSQoTAWinh4rglPaygRCOC/it91okTadmH3ACFkmWC1uNccX6h/9+rvZN5HBO0KoFcloJRZUYT9xp1yAKAUEioUv2y4n8TKdY4Ve4W0y6HtX7Rc228V+xxul6g/mcqphP2Ci6ASygnM7xf/vrHvk6Oc6VdYDsbntHJdn2F8n0i58Jyxcir+vTv/43a5xP9zrBwbDaRiWC3ub375FtQchWbLg0YYCqihNeBpBO9jnxPKJe0H+K+9yungeF4Qgtg51yDlNJputByC16T9wnJad0IgEz+j8zlvOZKPeCXZq+HQXdknNxwi+5kVc4+GQ2IFmtBwSCsXbxAkVrR9Gg6pDY5YwyGtXK8GQd5y8YZUr4ZDV4MqpeGgVI8Gh9Fw6NkwgaBeE0w1RiPDVov79FQD7zz75LLdGFuSKgUgWtmkvaZXZinlPECjT7kg/DOpnDYqrXbliB6VY+w1KfQ1MQY/KRw2IXw2bfm+pGOb5czQ10XPTQyVtSH0lWTDUYLr/uTskawFbbW4A8B800XL01EhiP+gkVMIYkKTWC5BaMxXDf848VZx3nL9BbbzhBL/rGPlUp9s+pRrf4bxZDPgE0rbP6PcKJ9QYByXTyjDY2gtaqMFnNSiztVSlvRXP7gt6k/aa1qXYuQpzCynkp/CurooVfTJSQSYrDvYNqJ5FFaL+w/2PoM/+uJd/IHmIIxBD+Pai/4AI4/6GX6AjhLUlaT2jRf9AaaWK/ADjJYLxx/iXRKdPn2/TKz7pEe5yOfwOsSEpGvcpf29ByvX/l5GOUhHtNPKhf6T6mO1uJ+5ZQ0+dvFvYqHlZZvK7qY/Yscfp9MesXvOgk04Xp5p7ktB6NcC/B9u+uQntCcgKek/EauWYhvmRKwsk8K6bE50W6JNRSdzKcOvmhLUHKYfIPZhtbivmarjj19zatlu9CVvv20vm5n2IG6Lpz0YdSVn2pquh7lm737kzjnS0ytUrC7EZN3BN99/Dk5aP1W2K4TkwmpxtwWlBAqCulO2J9VH6wTBD/PqJNi8oLLIamsnQdPaSIhm2ILkZ67nYd/BI7hx137MHpmnuBProLiTSiFBt0nnxiyvRvzuwwdx4679ABfIJhbCzkRCCBlDKO6EpNCJCqnYQAAhGaC4E9IXdssQ+6C4E0LIGEJxJ6Qv7JYh9kFxJySFdo87tZ1YCMWdkD5wtj2xEca5k3YCrX6Lg3fNnPWis1XjNrN8mYuVt1IWMO93joWWF1whqjuxj7EV93CmY54fc6Itxd5P1Mxzd2zBbMgUW+dYoc2cpt9t68zc7Myy9AXMn8YfztDMch2qihKgphSUCl6D5GOOUnBUZ1s034y/LZ6Dpl5XmEzLQZOSI2fNZB1nbBlN1j5CRonV4n7PY8/iT79yL+aablerrMJ6lRtHCRqOQqOmUHcUJmr++45NMDlRQ6PmBDZf4LqTYYUC2Ume5ScIU35yry4b4DjKSCSmIuWTbKEIZ7W1tyXYFDMQEjIwVov78dOTeOO/2oz5ppf6yJ235Z43addS4Hoac56LuaabeR8RtMXdbKUm2XplX1yqjI/t8yTY0jI49vtemc/NSoSMIVaL++Y1k/jEH7y0VB9yZ2TM2Z+cO0vjkCo58/Niy8tc8fW6DlV+mkoS/JqjsGayjuv+5Gwct2ZF2S4Skgurxb0KKCVoKLb6smBmfCw0rpEjFXE0G6RZARnZINtjHlHbgefm8O09B7H/0FGKO7EOijtZMrozPlab7++dxbf3HCzbDUIGgnHuhPSB3fHERmxpRJElZpSx78lhop1jLkXsuzkukDYe8cJiq+x/AyEDs6zEfSlj3xPXXU0UtdHFvkcHO72oWGe4DlUljHXPs4ZrWgRNo6Yw2SN6Z81kHds2ryn7KxOSm5GIu4hcBOCz8JfR+bzW+upRnOdHP38WH73pASy0ukMhk1plFdarnAs/h/Hgplh1YsSnarW2rROHLp3Y9YgtPK9vi4YkRm2pi0o7nTDEJFt4ji5bhjDFpOvAsEVC+jN0cRcRB8B/A3ABgP0A7haRW7TWDw37XPc//hwemX0Bf/Cy4zFRU5njmocVZ91P1BhnTQgpi1G03F8BYJ/W+lEAEJHrAVwCYOjiroNUrFe/5UysnFhWPUyEENKTUUTLbAHwuPF5f2CLICI7RGSXiOyanZ0d6ESnbFiFN565GQ7jzAkhJEJpzV2t9U4AOwFgZmZmoN7wC7ZtwgXbNg3VL0IIGQdG0XI/AOBE4/MJgY0QQsgSMQpxvxvAaSJyiog0ALwdwC0jOA8hhJAUht4to7VuicifAfgm/FDIL2qtHxz2eQghhKQzkj53rfWtAG4dxbEJIYT0h7llCCFkDKG4E0LIGEJxJ4SQMYTiTgghY4hoXX42LRGZBfBY2X7E2ADgmbKdyIFN/trkK0B/R4lNvgLV8/dkrfXGpA2VEPcqIiK7tNYzZfuRFZv8tclXgP6OEpt8Bezyl90yhBAyhlDcCSFkDKG4p7OzbAdyYpO/NvkK0N9RYpOvgEX+ss+dEELGELbcCSFkDKG4E0LIGLLsxF1EvigiB0XkJ4ZtnYjcJiJ7g9e1KftuD8rsFZHtJfr7VyLyUxF5QET+UUSmU/b9hYj8WETuE5FdJfn6SRE5EPhwn4hcnLLvRSLysIjsE5GrRu1rD39vMHz9hYjcl7LvUl/bE0XkDhF5SEQeFJErAnsl790e/lbu3u3ha2Xv3UxorZfVH4BzAJwF4CeG7TMArgreXwXg0wn7rQPwaPC6Nni/tiR/LwRQC95/OsnfYNsvAGwo+dp+EsCH+uznAHgEwKkAGgDuB7CtDH9j2/8TgH9XkWu7GcBZwfvVAH4GYFtV790e/lbu3u3ha2Xv3Sx/y67lrrW+E8CzMfMlAK4J3l8D4NKEXV8P4Dat9bNa60MAbgNw0cgcDUjyV2v9La11K/j4Q/irXZVOyrXNQntRda31IoBwUfWR0stfEREAbwNw3aj9yILW+kmt9b3B++cB7IG/NnEl7900f6t47/a4tlko5d7NwrIT9xQ2aa2fDN4/BSBpYdZMC3+XwLsB/HPKNg3gWyJyj4jsWEKf4vxZ8Bj+xZRugype29cAeFprvTdle2nXVkS2Ang5gLtgwb0b89ekcvdugq823rsAKO5daP9Zy4r4UBH5OIAWgGtTirxaa30WgDcAeK+InLNkznX4HIDfAPBbAJ6E39VhA3+I3q32Uq6tiKwC8A8A3q+1Pmxuq+K9m+ZvFe/dBF9tvXcBUNxDnhaRzQAQvB5MKFOphb9F5F0Afh/AO4IfdRda6wPB60EA/wj/EXJJ0Vo/rbV2tdYegP+Z4kPVrm0NwFsA3JBWpoxrKyJ1+OJzrdb6psBc2Xs3xd9K3rtJvtp475pQ3H1uARBGEGwHcHNCmW8CuFBE1gaPZxcGtiVHRC4C8GEAb9JaH00ps1JEVofv4fv7k6SyoyQUnoA3p/hQtUXVzwfwU631/qSNZVzbYAzgCwD2aK3/xthUyXs3zd8q3rs9fLXx3u1Q9ojuUv/Bf9R+EkATfv/Y5QDWA7gdwF4A3wawLig7A+Dzxr7vBrAv+LusRH/3we/nuy/4+7ug7PEAbg3enwp/5P5+AA8C+HhJvv4vAD8G8AD8m35z3Nfg88XwoxQeWQpf0/wN7F8G8J5Y2bKv7avhd7k8YPzfL67qvdvD38rduz18rey9m+WP6QcIIWQMYbcMIYSMIRR3QggZQyjuhBAyhlDcCSFkDKG4E0LIGEJxJ4SQMYTiTgghY8j/B/H/SRFkxhE/AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted translation:      \n",
            "Iteration :  100\n",
            "Loss :  tf.Tensor(17.440378, shape=(), dtype=float32)\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted translation:      \n",
            "Iteration :  110\n",
            "Loss :  tf.Tensor(17.46861, shape=(), dtype=float32)\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted translation:      \n",
            "Iteration :  120\n",
            "Loss :  tf.Tensor(17.441114, shape=(), dtype=float32)\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted ID :  0\n",
            "Predicted translation:      \n",
            "Iteration :  130\n",
            "Loss :  tf.Tensor(17.440594, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-8-3673f2d84efa>\", line 18, in <module>\n",
            "    network.train(X_train, Y_train, source_tok2ind, target_ind2tok, target_tok2ind, 50)\n",
            "  File \"<ipython-input-7-6817112ceec8>\", line 111, in train\n",
            "    batch_x, batch_y, start_index=target_tok2ind['<START>'], end_index=target_tok2ind['<END>'])\n",
            "  File \"<ipython-input-7-6817112ceec8>\", line 43, in train_step\n",
            "    prediction, dec_hidden, att_wt, state = self.decoder(dec_input, dec_hidden, enc_output, self.decoder_state)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 1012, in __call__\n",
            "    outputs = call_fn(inputs, *args, **kwargs)\n",
            "  File \"<ipython-input-6-4ebf93ce2199>\", line 94, in call\n",
            "    network.add(LSTM(units=128,activation='tanh',return_sequences=True))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/version_utils.py\", line 65, in __new__\n",
            "    cls = swap_class(cls, base_layer.Layer, base_layer_v1.Layer, use_v2)  # pylint: disable=self-cls-assignment\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/version_utils.py\", line 110, in swap_class\n",
            "    swap_class(base, v2_cls, v1_cls, use_v2) for base in cls.__bases__)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/version_utils.py\", line 110, in <genexpr>\n",
            "    swap_class(base, v2_cls, v1_cls, use_v2) for base in cls.__bases__)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/version_utils.py\", line 110, in swap_class\n",
            "    swap_class(base, v2_cls, v1_cls, use_v2) for base in cls.__bases__)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 739, in getmodule\n",
            "    f = getabsfile(module)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 708, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
            "    if os.path.exists(filename):\n",
            "  File \"/usr/lib/python3.7/genericpath.py\", line 18, in exists\n",
            "    try:\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BImWU6xKsBDJ",
        "outputId": "e1ade064-f3f4-4339-910f-d8ca03ba5f0a"
      },
      "source": [
        "%debug"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m<string>\u001b[0m(5)\u001b[0;36mraise_from\u001b[0;34m()\u001b[0m\n",
            "\n",
            "ipdb> k\n",
            "*** NameError: name 'k' is not defined\n",
            "ipdb> M\n",
            "*** NameError: name 'M' is not defined\n",
            "ipdb> quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4jR0lays34u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}